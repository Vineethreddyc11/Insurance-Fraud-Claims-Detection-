# Insurance-Fraud-Claims-Detection-

- Built machine learning model for enabling loss control units to achieve high coverage with low false positive rates to detect whether claim is genuine, or fraudulent based on data from an auto insurance company that has 40+ features and deployed using clouderizer. 

- Performed data manipulation, data preparation, normalization, predictive modeling, and EDA and implemented classification algorithms such as SVM, KNN, Decision tree, Random Forest, Gradient Boost, Ada Boost, XgBoost, SGM, LGBM classifiers.


## Problem Definition

The goal of this project is to build a model that can detect auto insurance fraud. The challenge behind fraud detection in machine learning is that frauds are far less common as compared to legit insurance claims.

Insurance fraud detection is a challenging problem, given the variety of fraud patterns and relatively small ratio of known frauds in typical samples. While building detection models, the savings from loss prevention needs to be balanced with the cost of false alerts. Machine learning techniques allow for improving predictive accuracy, enabling loss control units to achieve higher coverage with low false positive rates.

Insurance frauds cover the range of improper activities which an individual may commit in order to achieve a favourable outcome from the insurance company. This could range from staging the incident, misrepresenting the situation including the relevant actors and the cause of incident and finally the extent of damage caused.

## Data Analysis

In this project, I used dataset which has the details of the insurance policy along with the customer details. It also has the details of the accident on the basis of which the claims have been made.

The given dataset contains 40 columns. The column names like policy number, policy bind date, policy annual premium, incident severity, incident location, auto model, etc.

The obvious con of this data set is the small sample size. However, there are still many companies who do not have big data sets. The ability to work with what is available is crucial for any company looking to transition into leveraging data science.
